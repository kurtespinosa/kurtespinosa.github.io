<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title></title>
    <description></description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Letter to my friend</title>
        <description>&lt;p&gt;I have been around for around three decades on this earth and I have learned some valuable lessons which this life may have to teach us. And if anything, I would like to share it with you since what does a friend do but wish for his friend’s happiness too. I hope that from these small experiences and learnings you would also see how similar really our aspirations are in this life and maybe these you would be able to help you decide wisely what better road to take.&lt;/p&gt;

&lt;p&gt;I do not claim I have a full grasp of everything in this life but some things do make sense to me too invaluable not to share. First thing that is very clear to me is that everyone wants to be happy. All we do and our choices are guided by that inner principle. Take a moment to think about it. Everytime we make a choice, we think about it and everytime we think about something, we reflect if it will make us happy. Even at this point, it should be quite clear that making choices in this life requires some reasoning and then judgement. Hence, as a researcher would do it, it is very important to do a careful literature review to aid our reasoning process before we come up with the judgment. Maybe I am digressing too much from my main point but the point I’m driving at is that we need some background principles that would aid our reasoning and so that we can pass an informed judgment when we have to make choices in this life because what’s at stake is our happiness.&lt;/p&gt;

</description>
        <pubDate>Thu, 10 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/letter/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/letter/</guid>
      </item>
    
      <item>
        <title>Frontiers in Deep Learning and Reinforcement Learning</title>
        <description>&lt;p&gt;First of all, this post would not claim to exhaustively narrate everything discussed during the summer school. There are &lt;a href=&quot;https://mila.umontreal.ca/en/cours/deep-learning-summer-school-2017/schedule/&quot;&gt;slides&lt;/a&gt; and &lt;a href=&quot;http://videolectures.net/site/search/?q=deep+learning+summer+school&quot;&gt;video lectures&lt;/a&gt; for that and I highly recommend that you go thru them. Rather, in this post I will just mention ideas that are either: 1) new to me, 2) old but on which I have gained new perspective and deeper understanding 3) plain interesting. Some of these are mentioned in the slides or during the talk. Lastly, I do not claim that I have understood all the topics presented and what I am writing here are based solely on my understanding. Please refer to the actual slides or video lectures for a detailed treatment of each subject.&lt;/p&gt;

&lt;p&gt;The first part was about deep learning and the second part was on reinforcement learning.&lt;/p&gt;

&lt;p&gt;The first part started with an overview on Machine Learning by Dolna Precup (McGill University). She mentioned about parametric vs non-parametric models, bias-variance trade-off, regularisation, etc.&lt;/p&gt;

&lt;p&gt;The next part was an introduction to Neural Networks by Hugo Rochelle (Google Brain). He talked about the basics of neural network learning by backpropagation, etc. He also mentioned all the hyperparameters that need to be tuned especially during optimisation. At the end of his talk, he mentioned about one-shot or zero-shot learning and the need to design new architectures based on intuition.&lt;/p&gt;

&lt;p&gt;Yoshua Bengio (MILA, Uni of Montreal) gave the next talk on Recurrent Neural Networks. He mentioned about sequence-to-sequence network as a version of autoencoder-decoder. He also emphasised that the multiplicative interactions in the network increases expressive power. Regarding the gradients: on the one hand, if the eigen values are &amp;lt; 1, the gradient approaches zero, thus the vanishing gradient; on the other hand, if the eigen values are &amp;gt; 1, the gradient approaches infinity and thus the exploding gradient problem. He said that in GRUs gradients are copied instead of updated. Furthermore, he said that the main gate in the LSTM network is the forget gate and how the gates work are not yet fully understood. He also mentioned about the use of attention to make the network focus on important information in the network. (It is to be noted that he and his group pioneered both RNNs and attention mechanism.) Lastly, he said that backpropagation through time (BPTT), which is what happens in the RNNs, does not seem biologically plausible because our brain does not backpropagate the errors to the past in order to learn something. (During the summer school, Yoshua Bengio was awarded the Order of Canada for his contributions in this field.)&lt;/p&gt;

&lt;p&gt;The next talk was about Probabilistic Numerics by Mike Osborne (Oxford). This area sounds new to me but one thing that intrigued me was what he said: “integration beats optimisation”. He gave us the &lt;a href=&quot;http://probabilistic-numerics.org/&quot;&gt;link&lt;/a&gt; about this subject for those interested to go into this field.&lt;/p&gt;

&lt;p&gt;The next talk was about Generative Models by Ian Goodfellow (Google Brain). He began by describing the taxonomy of generative models and then explained how Generative Adversarial Networks (GANs) work. What interested me is the idea that GANs can be used to generate models for simulated training data. In his second talk, he discussed all the state-of-the-art in GANs such as PixelCNN.&lt;/p&gt;

&lt;p&gt;The next talk was given my Mike Osborne (Oxford) about the Future of Work. He presented statistics on which profession will likely be affected by the coming of intelligent machine age but he also emphasised that though this may happen, history shows that new jobs also come out and that it is up to the policy-makers to manage the transition well. He also said that while we have advanced dramatically in AI, having a cleaning assistant robot in the house would not be feasible even in 20-30 years for that seemingly simple job.&lt;/p&gt;

&lt;p&gt;The next talk was about Convolutional Neural Networks (CNN) by Richard Zemel (Uni of Toronto). He talked about the advances in CNN but one particular thing that was interesting to me was about highway networks which could be used to dynamically determine when data is passed thru or transferred.&lt;/p&gt;

&lt;p&gt;Raquel Urtasun (Head, Uber Toronto; Prof, Uni of Toronto) gave the next talk about Deep Structured Models. She emphasised that the outputs for these models are statistically dependent. Problems having a structure in the output are usually approached using Markov Random Fields (MRFs) but as a post-processing step. The complex dependencies wherein multiple variables are predicted fits nicely with the idea of using graphical models and thus its natural connection to deep learning. With deep structured models, complex dependencies can be modeled using one loss function much like in a multi-task learning fashion. Her advice in exploring this convergence of the two fields of graphical models and deep learning is to think how to encode what we know and we don’t know about the problem. At the end, she mentioned about the energy models as a way of looking at the loss functions.&lt;/p&gt;

&lt;p&gt;The next talk was on Natural Language Processing by Phil Blunsom (Oxford). He first differentiated computational linguistics from natural language processing. He then talked about language modelling and he mentioned that there are better datasets for this task such as the WikiText and that we should not use the old-fashioned PTB or similar ones anymore because of the inherent biases present in the data. In talking about language modelling, he mentioned the evolution of methods from n-gram models to neural models and now we have RNNs and more sophisticated versions such as recurrent highway networks which is the state-of-the-art on this task.&lt;/p&gt;

&lt;p&gt;In the second part of his talk, he discussed the advances of NLP and the frontiers. For example, he talked about what actually is limiting us - is it the thought or the syntax? He suggested that GANs may be useful in modelling structures. He mentioned a recent work on learning word compositionality in sentences in which reinforcement learning was used to select structures that maximises task-based rewards. Generally, how to capture the structure is still an open problem. He mentioned their research on grounding words to learn their meaning, i.e., they experimented with linguistic symbols in order to interpret meaning of utterance. However, to emphasise the complexity of the problem, language acquisition is an open problem in itself. He mentioned lots of researches done in psychology on language acquisition.&lt;/p&gt;

&lt;p&gt;The next talk was about Computational Neuroscience by Blake Richards and Surya Ganguli. The emphasis of this talk was on how neuroscience can learn 222from deep learning and vice versa.&lt;/p&gt;

&lt;p&gt;The other talks include Graphical Models + Deep Learning by Max Welling and Matt Johnson, Learning to Learn by Nando Freitas where he emphasised that a truly end-to-end learning only happens if it includes parameter learning as well.&lt;/p&gt;

&lt;p&gt;The second part which is on Reinforcement Learning was started by Joelle Pineau (McGill University). She gave a very good introduction to the subject especially differentiating the jargons involved. Pieter Abbeel (UC Berkeley) then gave a talk on Policy Search, followed by Rich Sutton’s talk on TD learning. Much of the content were new to me so it would be redundant to repeat them all here:)&lt;/p&gt;

&lt;p&gt;The most interesting ideas in this summer school which are relevant to my research at this point comes from the talks on GANs, grounding, deep structured models and RL.&lt;/p&gt;

&lt;p&gt;To all the organisers of the summer school, I could not thank you more. I felt I was so lucky to be among the few admitted to attend it. The summer school has opened to me the vast horizon of research frontiers in this field.&lt;/p&gt;

</description>
        <pubDate>Wed, 12 Jul 2017 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/dlrlss/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/dlrlss/</guid>
      </item>
    
      <item>
        <title>What was the COLING for me?</title>
        <description>&lt;p&gt;It was a terribly good experience! Understanding sentences like that remains one of the challenges in Natural Language Processing (NLP) in general based on my impression after attending the Computational Linguistics (COLING) conference held at Osaka, Japan from Dec 10-16, 2016. In this post, I aim to summarise my learning experiences in COLING.&lt;/p&gt;

&lt;p&gt;My proposed topic (semantic similarity) is a core problem in many high-level semantic applications such as question answering, summarisation, entailment, translation, etc. In fact, my observation is confirmed by &lt;a href=&quot;https://levyomer.wordpress.com/bio/&quot;&gt;Omer Levy&lt;/a&gt; (University of Washington and Bar-Ilan University, Israel) whom I also met during the conference.&lt;/p&gt;

&lt;p&gt;I also had a short discussion with  &lt;a href=&quot;https://levyomer.wordpress.com/bio/&quot;&gt;Omer Levy&lt;/a&gt;, &lt;a href=&quot;http://pontus.stenetorp.se/&quot;&gt;Pontus Stenetorp&lt;/a&gt; (UCL) and &lt;a href=&quot;http://www.eecs.qmul.ac.uk/people/view/45712/dimitrios-kartsaklis&quot;&gt;Dimitrios Kartsaklis&lt;/a&gt; (Queen Mary University of London) among others about sentence compositionally on what they think about it. They know the problem well and just simply responded what would be an alternative. I proposed that it should stop at semantic units (which could be at the sentence level) and from there do the alignments. I shared this intuition with Omer and Dimitrios at least in my impression.&lt;/p&gt;

&lt;p&gt;I also discovered interesting and intuitive deep learning architectures for capturing language intuitions. I’m listing down below the especially interesting ones for me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Using attention to dynamically decide between character or word embeddings on the input representation by &lt;a href=&quot;http://www.marekrei.com/&quot;&gt;Marek Rei&lt;/a&gt; (University of Cambridge). &lt;a href=&quot;https://arxiv.org/abs/1611.04361&quot;&gt;Attending to Characters in Neural Sequence Labeling Models&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Using orthographic sequence representation to capture noise in twitter by &lt;a href=&quot;http://www.dcs.gla.ac.uk/~nutli/&quot;&gt;Nut Limsopatham&lt;/a&gt; (University of Cambridge). &lt;a href=&quot;http://noisy-text.github.io/2016/pdf/WNUT20.pdf&quot;&gt;Bidirectional LSTM for Named Entity Recognition in Twitter Messages&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lexical Decomposition and Composition by &lt;a href=&quot;http://researcher.watson.ibm.com/researcher/view.php?person=us-zhigwang&quot;&gt;Zhiguo Wang&lt;/a&gt; (IBM New York). &lt;a href=&quot;https://arxiv.org/abs/1602.07019&quot;&gt;Sentence Similarity Learning by Lexical Decomposition and Composition&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Re-reading of sentence according to memory of another sentence for better understanding by &lt;a href=&quot;http://shalei120.github.io/&quot;&gt;Lei Sha&lt;/a&gt; et al (Peking University). &lt;a href=&quot;http://www.aclweb.org/anthology/C/C16/C16-1270.pdf&quot;&gt;Reading and Thinking: Re-read LSTM Unit for Textual Entailment Recognition&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Alignment with implicit distortion and fertility using attention by Shi Feng et al (University of Maryland College Park). &lt;a href=&quot;http://www.aclweb.org/anthology/C/C16/C16-1290.pdf&quot;&gt;Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Applying attention to tree structures by &lt;a href=&quot;http://kaizhao.me/&quot;&gt;Kai Zhao&lt;/a&gt; (Oregon State University). &lt;a href=&quot;http://kaizhao.me/files/structured-attention.pdf&quot;&gt;Textual Entailment with Structured Attentions and Composition&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I also found interesting studies that try to capture linguistic notions from humans and behaviour.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Omer Levy on using subtree entailment to extract sentence intersection. &lt;a href=&quot;https://levyomer.files.wordpress.com/2016/12/modeling-extractive-sentence-intersection-via-subtree-entailment-coling-2016.pdf&quot;&gt;Modeling Extractive Sentence Intersection via Subtree Entailment&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.let.rug.nl/~bplank/&quot;&gt;Barbara Plank&lt;/a&gt; (University of Groningen, Netherlands) on modelling syntactic parsing via keystroke dynamics. &lt;a href=&quot;https://arxiv.org/abs/1610.03321&quot;&gt;Keystroke dynamics as signal for shallow syntactic parsing&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lieke Gelderloos (Tilburg University, Netherlands) on levels of representations of RNN using images and phonemes. &lt;a href=&quot;https://arxiv.org/abs/1610.03342&quot;&gt;From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.linguist.univ-paris-diderot.fr/~mcandito/&quot;&gt;Marie Candito&lt;/a&gt; (Université Paris Diderot) used syntactic rules for semantic parsing. &lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-01391678/document&quot;&gt;Deeper syntax for better semantic parsing&lt;/a&gt;. If it is possible to model this using deep neural networks, then it would be great!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Related to this, I was thinking of doing an experiment that simulates alignment. It should simulate aspects of iSTS such as alignment type. Further, timestamp should be noted to indicate the order of importance when doing alignment. 
In addition, I wonder also if the work of Barbara could be done for speech for the same task of shallow syntactic parsing.&lt;/p&gt;

&lt;p&gt;Further, there were some studies focusing more on machine learning.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://martenpostma.com/&quot;&gt;Marten Postma&lt;/a&gt; (Vrije Universiteit Amsterdam, Netherlands) More data does not always result to better performance since most frequently occurring word-sense gets selected. The conclusion is that acquisition of training data must be guided by the task at hand. &lt;a href=&quot;http://www.aclweb.org/anthology/C/C16/C16-1330.pdf&quot;&gt;More is not always better: balancing sense distributions for all-words Word Sense Disambiguation&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.uva.nl/over-de-uva/organisatie/medewerkers/content/s/c/p.schulz/p.schulz.html&quot;&gt;Philip Schulz&lt;/a&gt; (University of Amsterdam) on word alignment using HMM and language model. &lt;a href=&quot;http://wilkeraziz.github.io/papers/coling2016.pdf&quot;&gt;Fast Collocation-Based Bayesian HMM Word Alignment&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And some datasets.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.derczynski.com/sheffield/&quot;&gt;Leon Derczynski&lt;/a&gt; (University of Sheffield, UK). Twitter corpus that is more representative spatially and temporally. &lt;a href=&quot;http://www.derczynski.com/sheffield/papers/btc.pdf&quot;&gt;Broad Twitter Corpus: A Diverse Named Entity Recognition Resource&lt;/a&gt;. The dataset is free and spans 5 years beginning 2009.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Had a short chat with &lt;a href=&quot;http://cental.fltr.ucl.ac.be/team/tfrancois/&quot;&gt;Thomas Francois&lt;/a&gt; (UCL, Belgium) on the possibility of teaching machines like teaching kids to read which is to start from simple sentences and he referred to me a dataset: weekly reader and BBC bitesize. This would be an interesting research.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I also met some fantastic people from industry like the CEO and Co-founder of Chata.ai (based in Calgary, Canada), &lt;a href=&quot;https://www.linkedin.com/in/kelly-cherniwchan-2969426/&quot;&gt;Kelly Cherniwchan&lt;/a&gt;. Imagine a question-answering system that interacts with your database.&lt;/p&gt;

&lt;p&gt;Here is the &lt;a href=&quot;http://coling2016.anlp.jp/doc/main.pdf&quot;&gt;COLING 2016 proceedings&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Lastly, the list of upcoming conferences was announced at the closing event as follows:&lt;/p&gt;

&lt;p&gt;EACL 2017. April 3-7, Spain. Deadline passed.&lt;/p&gt;

&lt;p&gt;ACL 2017. July 30-Aug 4, Vancouver. Deadline: Feb 6, 2017.&lt;/p&gt;

&lt;p&gt;EMNLP 2017. Sep 9-11, Copenhagen. Deadline: April 14, 2017.&lt;/p&gt;

&lt;p&gt;COLING 2018. Sta Fe, USA. TBA.&lt;/p&gt;

&lt;p&gt;Attending conferences indeed is very expensive but I think it is the most efficient way to get new ideas and to know the state-of-the-art in my field through the face-to-face interaction with the experts themselves in the field.&lt;/p&gt;

</description>
        <pubDate>Sat, 17 Dec 2016 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2016/coling/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/coling/</guid>
      </item>
    
      <item>
        <title>K-fold Cross Validation in Neural Networks</title>
        <description>&lt;p&gt;What I want to explain here is how to use K-fold cross validation in neural networks. We know that in neural networks, we use the back propagation algorithm to adjust the weights or parameters of the neural network as many times until the error (i.e. the difference of the predicted output and expected output values) are small enough for us. I will call these set of parameters/weights in the neural network as simply model parameters.&lt;/p&gt;

&lt;p&gt;Now, we have heard as well that K-fold cross validation can help determine the best model parameters, that is the set of model parameters that can generalise(i.e. perform well) on unseen data(e.g. held-out test set). So the question is: how can we use K-fold cross validation to do that?&lt;/p&gt;

&lt;p&gt;For example, you were given tweets and the task is named entity recognition (NER). Each tweet has been tokenized and each token labeled with a particular entity type (e.g. location, person, organization, etc). So how do you proceed?&lt;/p&gt;

&lt;p&gt;Using neural network, here’s how you should proceed:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Split the data into k-folds and each fold has train, dev, and test set.&lt;/li&gt;
  &lt;li&gt;For each fold, within an epoch loop, train the neural network parameters with the training set and decide whether to continue training using the dev set. Finally at the end of every epoch, you can test the model performance by using the test set.&lt;/li&gt;
  &lt;li&gt;Compute the final f-score using method 3 in this &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=DA673A6EA027C2E8B1831FD9B9A24A0C?doi=10.1.1.186.8880&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;paper&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Retrain the whole dataset using the neural network param with the best f-score.&lt;/li&gt;
  &lt;li&gt;That’s it! You have the model which can generalise to unseen examples.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://cs229.stanford.edu/notes/cs229-notes5.pdf&quot;&gt;http://cs229.stanford.edu/notes/cs229-notes5.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=DA673A6EA027C2E8B1831FD9B9A24A0C?doi=10.1.1.186.8880&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=DA673A6EA027C2E8B1831FD9B9A24A0C?doi=10.1.1.186.8880&amp;amp;rep=rep1&amp;amp;type=pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jamesmccaffrey.wordpress.com/2013/10/25/k-fold-cross-validation-for-neural-networks/&quot;&gt;https://jamesmccaffrey.wordpress.com/2013/10/25/k-fold-cross-validation-for-neural-networks/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://artint.info/html/ArtInt_189.html&quot;&gt;http://artint.info/html/ArtInt_189.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.quora.com/Why-do-we-have-separation-of-data-into-training-held-out-and-test-data&quot;&gt;https://www.quora.com/Why-do-we-have-separation-of-data-into-training-held-out-and-test-data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-networ&quot;&gt;https://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-networ&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sat, 20 Aug 2016 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2016/kfold/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/kfold/</guid>
      </item>
    
  </channel>
</rss>
